Augmenting Neural Response Generation with Context-Aware Topical
  Attention
Sequence-to-Sequence (Seq2Seq) models have witnessed a notable success in
generating natural conversational exchanges. Notwithstanding the syntactically
well-formed responses generated by these neural network models, they are prone
to be acontextual, short and generic. In this work, we introduce a Topical
Hierarchical Recurrent Encoder Decoder (THRED), a novel, fully data-driven,
multi-turn response generation system intended to produce contextual and
topic-aware responses. Our model is built upon the basic Seq2Seq model by
augmenting it with a hierarchical joint attention mechanism that incorporates
topical concepts and previous interactions into the response generation. To
train our model, we provide a clean and high-quality conversational dataset
mined from Reddit comments. We evaluate THRED on two novel automated metrics,
dubbed Semantic Similarity and Response Echo Index, as well as with human
evaluation. Our experiments demonstrate that the proposed model is able to
generate more diverse and contextually relevant responses compared to the
strong baselines.