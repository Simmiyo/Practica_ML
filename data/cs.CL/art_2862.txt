Neural-based Context Representation Learning for Dialog Act
  Classification
We explore context representation learning methods in neural-based models for
dialog act classification. We propose and compare extensively different methods
which combine recurrent neural network architectures and attention mechanisms
(AMs) at different context levels. Our experimental results on two benchmark
datasets show consistent improvements compared to the models without contextual
information and reveal that the most suitable AM in the architecture depends on
the nature of the dataset.