Representation Learning Models for Entity Search
We focus on the problem of learning distributed representations for entity
search queries, named entities, and their short descriptions. With our
representation learning models, the entity search query, named entity and
description can be represented as low-dimensional vectors. Our goal is to
develop a simple but effective model that can make the distributed
representations of query related entities similar to the query in the vector
space. Hence, we propose three kinds of learning strategies, and the difference
between them mainly lies in how to deal with the relationship between an entity
and its description. We analyze the strengths and weaknesses of each learning
strategy and validate our methods on public datasets which contain four kinds
of named entities, i.e., movies, TV shows, restaurants and celebrities. The
experimental results indicate that our proposed methods can adapt to different
types of entity search queries, and outperform the current state-of-the-art
methods based on keyword matching and vanilla word2vec models. Besides, the
proposed methods can be trained fast and be easily extended to other similar
tasks.