Aspect-augmented Adversarial Networks for Domain Adaptation
We introduce a neural method for transfer learning between two (source and
target) classification tasks or aspects over the same domain. Rather than
training on target labels, we use a few keywords pertaining to source and
target aspects indicating sentence relevance instead of document class labels.
Documents are encoded by learning to embed and softly select relevant sentences
in an aspect-dependent manner. A shared classifier is trained on the source
encoded documents and labels, and applied to target encoded documents. We
ensure transfer through aspect-adversarial training so that encoded documents
are, as sets, aspect-invariant. Experimental results demonstrate that our
approach outperforms different baselines and model variants on two datasets,
yielding an improvement of 27% on a pathology dataset and 5% on a review
dataset.