Deep Graph Convolutional Encoders for Structured Data to Text Generation
Most previous work on neural text generation from graph-structured data
relies on standard sequence-to-sequence methods. These approaches linearise the
input graph to be fed to a recurrent neural network. In this paper, we propose
an alternative encoder based on graph convolutional networks that directly
exploits the input structure. We report results on two graph-to-sequence
datasets that empirically show the benefits of explicitly encoding the input
graph structure.