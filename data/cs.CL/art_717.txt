Integrative Semantic Dependency Parsing via Efficient Large-scale
  Feature Selection
Semantic parsing, i.e., the automatic derivation of meaning representation
such as an instantiated predicate-argument structure for a sentence, plays a
critical role in deep processing of natural language. Unlike all other top
systems of semantic dependency parsing that have to rely on a pipeline
framework to chain up a series of submodels each specialized for a specific
subtask, the one presented in this article integrates everything into one
model, in hopes of achieving desirable integrity and practicality for real
applications while maintaining a competitive performance. This integrative
approach tackles semantic parsing as a word pair classification problem using a
maximum entropy classifier. We leverage adaptive pruning of argument candidates
and large-scale feature selection engineering to allow the largest feature
space ever in use so far in this field, it achieves a state-of-the-art
performance on the evaluation data set for CoNLL-2008 shared task, on top of
all but one top pipeline system, confirming its feasibility and effectiveness.