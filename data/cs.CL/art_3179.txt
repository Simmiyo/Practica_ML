BENGAL: An Automatic Benchmark Generator for Entity Recognition and
  Linking
The manual creation of gold standards for named entity recognition and entity
linking is time- and resource-intensive. Moreover, recent works show that such
gold standards contain a large proportion of mistakes in addition to being
difficult to maintain. We hence present BENGAL, a novel automatic generation of
such gold standards as a complement to manually created benchmarks. The main
advantage of our benchmarks is that they can be readily generated at any time.
They are also cost-effective while being guaranteed to be free of annotation
errors. We compare the performance of 11 tools on benchmarks in English
generated by BENGAL and on 16benchmarks created manually. We show that our
approach can be ported easily across languages by presenting results achieved
by 4 tools on both Brazilian Portuguese and Spanish. Overall, our results
suggest that our automatic benchmark generation approach can create varied
benchmarks that have characteristics similar to those of existing benchmarks.
Our approach is open-source. Our experimental results are available at
http://faturl.com/bengalexpinlg and the code at
https://github.com/dice-group/BENGAL.