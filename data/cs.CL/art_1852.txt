Exploiting Multi-typed Treebanks for Parsing with Deep Multi-task
  Learning
Various treebanks have been released for dependency parsing. Despite that
treebanks may belong to different languages or have different annotation
schemes, they contain syntactic knowledge that is potential to benefit each
other. This paper presents an universal framework for exploiting these
multi-typed treebanks to improve parsing with deep multi-task learning. We
consider two kinds of treebanks as source: the multilingual universal treebanks
and the monolingual heterogeneous treebanks. Multiple treebanks are trained
jointly and interacted with multi-level parameter sharing. Experiments on
several benchmark datasets in various languages demonstrate that our approach
can make effective use of arbitrary source treebanks to improve target parsing
models.