Task-Specific Attentive Pooling of Phrase Alignments Contributes to
  Sentence Matching
This work studies comparatively two typical sentence matching tasks: textual
entailment (TE) and answer selection (AS), observing that weaker phrase
alignments are more critical in TE, while stronger phrase alignments deserve
more attention in AS. The key to reach this observation lies in phrase
detection, phrase representation, phrase alignment, and more importantly how to
connect those aligned phrases of different matching degrees with the final
classifier. Prior work (i) has limitations in phrase generation and
representation, or (ii) conducts alignment at word and phrase levels by
handcrafted features or (iii) utilizes a single framework of alignment without
considering the characteristics of specific tasks, which limits the framework's
effectiveness across tasks. We propose an architecture based on Gated Recurrent
Unit that supports (i) representation learning of phrases of arbitrary
granularity and (ii) task-specific attentive pooling of phrase alignments
between two sentences. Experimental results on TE and AS match our observation
and show the effectiveness of our approach.