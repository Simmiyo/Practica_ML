Evaluating Word Embedding Hyper-Parameters for Similarity and Analogy
  Tasks
The versatility of word embeddings for various applications is attracting
researchers from various fields. However, the impact of hyper-parameters when
training embedding model is often poorly understood. How much do
hyper-parameters such as vector dimensions and corpus size affect the quality
of embeddings, and how do these results translate to downstream applications?
Using standard embedding evaluation metrics and datasets, we conduct a study to
empirically measure the impact of these hyper-parameters.