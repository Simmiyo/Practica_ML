On Structured Sparsity of Phonological Posteriors for Linguistic Parsing
The speech signal conveys information on different time scales from short
time scale or segmental, associated to phonological and phonetic information to
long time scale or supra segmental, associated to syllabic and prosodic
information. Linguistic and neurocognitive studies recognize the phonological
classes at segmental level as the essential and invariant representations used
in speech temporal organization. In the context of speech processing, a deep
neural network (DNN) is an effective computational method to infer the
probability of individual phonological classes from a short segment of speech
signal. A vector of all phonological class probabilities is referred to as
phonological posterior. There are only very few classes comprising a short term
speech signal; hence, the phonological posterior is a sparse vector. Although
the phonological posteriors are estimated at segmental level, we claim that
they convey supra-segmental information. Specifically, we demonstrate that
phonological posteriors are indicative of syllabic and prosodic events.
Building on findings from converging linguistic evidence on the gestural model
of Articulatory Phonology as well as the neural basis of speech perception, we
hypothesize that phonological posteriors convey properties of linguistic
classes at multiple time scales, and this information is embedded in their
support (index) of active coefficients. To verify this hypothesis, we obtain a
binary representation of phonological posteriors at the segmental level which
is referred to as first-order sparsity structure; the high-order structures are
obtained by the concatenation of first-order binary vectors. It is then
confirmed that the classification of supra-segmental linguistic events, the
problem known as linguistic parsing, can be achieved with high accuracy using
asimple binary pattern matching of first-order or high-order structures.