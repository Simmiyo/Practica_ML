CRNN: A Joint Neural Network for Redundancy Detection
This paper proposes a novel framework for detecting redundancy in supervised
sentence categorisation. Unlike traditional singleton neural network, our model
incorporates character-aware convolutional neural network (Char-CNN) with
character-aware recurrent neural network (Char-RNN) to form a convolutional
recurrent neural network (CRNN). Our model benefits from Char-CNN in that only
salient features are selected and fed into the integrated Char-RNN. Char-RNN
effectively learns long sequence semantics via sophisticated update mechanism.
We compare our framework against the state-of-the-art text classification
algorithms on four popular benchmarking corpus. For instance, our model
achieves competing precision rate, recall ratio, and F1 score on the
Google-news data-set. For twenty-news-groups data stream, our algorithm obtains
the optimum on precision rate, recall ratio, and F1 score. For Brown Corpus,
our framework obtains the best F1 score and almost equivalent precision rate
and recall ratio over the top competitor. For the question classification
collection, CRNN produces the optimal recall rate and F1 score and comparable
precision rate. We also analyse three different RNN hidden recurrent cells'
impact on performance and their runtime efficiency. We observe that MGU
achieves the optimal runtime and comparable performance against GRU and LSTM.
For TFIDF based algorithms, we experiment with word2vec, GloVe, and sent2vec
embeddings and report their performance differences.