Multi-Layer Ensembling Techniques for Multilingual Intent Classification
In this paper we determine how multi-layer ensembling improves performance on
multilingual intent classification. We develop a novel multi-layer ensembling
approach that ensembles both different model initializations and different
model architectures. We also introduce a new banking domain dataset and compare
results against the standard ATIS dataset and the Chinese SMP2017 dataset to
determine ensembling performance in multilingual and multi-domain contexts. We
run ensemble experiments across all three datasets, and conclude that
ensembling provides significant performance increases, and that multi-layer
ensembling is a no-risk way to improve performance on intent classification. We
also find that a diverse ensemble of simple models can reach perform comparable
to much more sophisticated state-of-the-art models. Our best F 1 scores on
ATIS, Banking, and SMP are 97.54%, 91.79%, and 93.55% respectively, which
compare well with the state-of-the-art on ATIS and best submission to the
SMP2017 competition. The total ensembling performance increases we achieve are
0.23%, 1.96%, and 4.04% F 1 respectively.