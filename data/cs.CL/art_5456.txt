Filling Gender & Number Gaps in Neural Machine Translation with
  Black-box Context Injection
When translating from a language that does not morphologically mark
information such as gender and number into a language that does, translation
systems must "guess" this missing information, often leading to incorrect
translations in the given context. We propose a black-box approach for
injecting the missing information to a pre-trained neural machine translation
system, allowing to control the morphological variations in the generated
translations without changing the underlying model or training data. We
evaluate our method on an English to Hebrew translation task, and show that it
is effective in injecting the gender and number information and that supplying
the correct information improves the translation accuracy in up to 2.3 BLEU on
a female-speaker test set for a state-of-the-art online black-box system.
Finally, we perform a fine-grained syntactic analysis of the generated
translations that shows the effectiveness of our method.