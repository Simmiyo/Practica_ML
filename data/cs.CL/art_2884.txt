Fluency-Guided Cross-Lingual Image Captioning
Image captioning has so far been explored mostly in English, as most
available datasets are in this language. However, the application of image
captioning should not be restricted by language. Only few studies have been
conducted for image captioning in a cross-lingual setting. Different from these
works that manually build a dataset for a target language, we aim to learn a
cross-lingual captioning model fully from machine-translated sentences. To
conquer the lack of fluency in the translated sentences, we propose in this
paper a fluency-guided learning framework. The framework comprises a module to
automatically estimate the fluency of the sentences and another module to
utilize the estimated fluency scores to effectively train an image captioning
model for the target language. As experiments on two bilingual
(English-Chinese) datasets show, our approach improves both fluency and
relevance of the generated captions in Chinese, but without using any manually
written sentences from the target language.