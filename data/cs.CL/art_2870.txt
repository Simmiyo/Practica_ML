Making Sense of Word Embeddings
We present a simple yet effective approach for learning word sense
embeddings. In contrast to existing techniques, which either directly learn
sense representations from corpora or rely on sense inventories from lexical
resources, our approach can induce a sense inventory from existing word
embeddings via clustering of ego-networks of related words. An integrated WSD
mechanism enables labeling of words in context with learned sense vectors,
which gives rise to downstream applications. Experiments show that the
performance of our method is comparable to state-of-the-art unsupervised WSD
systems.