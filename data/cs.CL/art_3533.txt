The Geometry of Culture: Analyzing Meaning through Word Embeddings
We demonstrate the utility of a new methodological tool, neural-network word
embedding models, for large-scale text analysis, revealing how these models
produce richer insights into cultural associations and categories than possible
with prior methods. Word embeddings represent semantic relations between words
as geometric relationships between vectors in a high-dimensional space,
operationalizing a relational model of meaning consistent with contemporary
theories of identity and culture. We show that dimensions induced by word
differences (e.g. man - woman, rich - poor, black - white, liberal -
conservative) in these vector spaces closely correspond to dimensions of
cultural meaning, and the projection of words onto these dimensions reflects
widely shared cultural connotations when compared to surveyed responses and
labeled historical data. We pilot a method for testing the stability of these
associations, then demonstrate applications of word embeddings for
macro-cultural investigation with a longitudinal analysis of the coevolution of
gender and class associations in the United States over the 20th century and a
comparative analysis of historic distinctions between markers of gender and
class in the U.S. and Britain. We argue that the success of these
high-dimensional models motivates a move towards "high-dimensional theorizing"
of meanings, identities and cultural processes.