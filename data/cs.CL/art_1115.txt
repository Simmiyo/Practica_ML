Effective LSTMs for Target-Dependent Sentiment Classification
Target-dependent sentiment classification remains a challenge: modeling the
semantic relatedness of a target with its context words in a sentence.
Different context words have different influences on determining the sentiment
polarity of a sentence towards the target. Therefore, it is desirable to
integrate the connections between target word and context words when building a
learning system. In this paper, we develop two target dependent long short-term
memory (LSTM) models, where target information is automatically taken into
account. We evaluate our methods on a benchmark dataset from Twitter. Empirical
results show that modeling sentence representation with standard LSTM does not
perform well. Incorporating target information into LSTM can significantly
boost the classification accuracy. The target-dependent LSTM models achieve
state-of-the-art performances without using syntactic parser or external
sentiment lexicons.