A neural interlingua for multilingual machine translation
We incorporate an explicit neural interlingua into a multilingual
encoder-decoder neural machine translation (NMT) architecture. We demonstrate
that our model learns a language-independent representation by performing
direct zero-shot translation (without using pivot translation), and by using
the source sentence embeddings to create an English Yelp review classifier
that, through the mediation of the neural interlingua, can also classify French
and German reviews. Furthermore, we show that, despite using a smaller number
of parameters than a pairwise collection of bilingual NMT models, our approach
produces comparable BLEU scores for each language pair in WMT15.