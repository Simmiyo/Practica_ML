Lexico-acoustic Neural-based Models for Dialog Act Classification
Recent works have proposed neural models for dialog act classification in
spoken dialogs. However, they have not explored the role and the usefulness of
acoustic information. We propose a neural model that processes both lexical and
acoustic features for classification. Our results on two benchmark datasets
reveal that acoustic features are helpful in improving the overall accuracy.
Finally, a deeper analysis shows that acoustic features are valuable in three
cases: when a dialog act has sufficient data, when lexical information is
limited and when strong lexical cues are not present.