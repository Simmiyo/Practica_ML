Sememe Prediction: Learning Semantic Knowledge from Unstructured Textual
  Wiki Descriptions
Huge numbers of new words emerge every day, leading to a great need for
representing them with semantic meaning that is understandable to NLP systems.
Sememes are defined as the minimum semantic units of human languages, the
combination of which can represent the meaning of a word. Manual construction
of sememe based knowledge bases is time-consuming and labor-intensive.
Fortunately, communities are devoted to composing the descriptions of words in
the wiki websites. In this paper, we explore to automatically predict lexical
sememes based on the descriptions of the words in the wiki websites. We view
this problem as a weakly ordered multi-label task and propose a Label
Distributed seq2seq model (LD-seq2seq) with a novel soft loss function to solve
the problem. In the experiments, we take a real-world sememe knowledge base
HowNet and the corresponding descriptions of the words in Baidu Wiki for
training and evaluation. The results show that our LD-seq2seq model not only
beats all the baselines significantly on the test set, but also outperforms
amateur human annotators in a random subset of the test set.