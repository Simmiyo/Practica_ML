Learning Noun Cases Using Sequential Neural Networks
Morphological declension, which aims to inflect nouns to indicate number,
case and gender, is an important task in natural language processing (NLP).
This research proposal seeks to address the degree to which Recurrent Neural
Networks (RNNs) are efficient in learning to decline noun cases. Given the
challenge of data sparsity in processing morphologically rich languages and
also, the flexibility of sentence structures in such languages, we believe that
modeling morphological dependencies can improve the performance of neural
network models. It is suggested to carry out various experiments to understand
the interpretable features that may lead to a better generalization of the
learned models on cross-lingual tasks.