Room for improvement in automatic image description: an error analysis
In recent years we have seen rapid and significant progress in automatic
image description but what are the open problems in this area? Most work has
been evaluated using text-based similarity metrics, which only indicate that
there have been improvements, without explaining what has improved. In this
paper, we present a detailed error analysis of the descriptions generated by a
state-of-the-art attention-based model. Our analysis operates on two levels:
first we check the descriptions for accuracy, and then we categorize the types
of errors we observe in the inaccurate descriptions. We find only 20% of the
descriptions are free from errors, and surprisingly that 26% are unrelated to
the image. Finally, we manually correct the most frequently occurring error
types (e.g. gender identification) to estimate the performance reward for
addressing these errors, observing gains of 0.2--1 BLEU point per type.