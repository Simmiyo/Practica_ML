The University of Cambridge's Machine Translation Systems for WMT18
The University of Cambridge submission to the WMT18 news translation task
focuses on the combination of diverse models of translation. We compare
recurrent, convolutional, and self-attention-based neural models on
German-English, English-German, and Chinese-English. Our final system combines
all neural models together with a phrase-based SMT system in an MBR-based
scheme. We report small but consistent gains on top of strong Transformer
ensembles.