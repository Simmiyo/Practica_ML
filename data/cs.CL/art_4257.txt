Low-Resource Contextual Topic Identification on Speech
In topic identification (topic ID) on real-world unstructured audio, an audio
instance of variable topic shifts is first broken into sequential segments, and
each segment is independently classified. We first present a general purpose
method for topic ID on spoken segments in low-resource languages, using a
cascade of universal acoustic modeling, translation lexicons to English, and
English-language topic classification. Next, instead of classifying each
segment independently, we demonstrate that exploring the contextual
dependencies across sequential segments can provide large improvements. In
particular, we propose an attention-based contextual model which is able to
leverage the contexts in a selective manner. We test both our contextual and
non-contextual models on four LORELEI languages, and on all but one our
attention-based contextual model significantly outperforms the
context-independent models.