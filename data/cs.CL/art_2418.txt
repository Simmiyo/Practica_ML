Deep LSTM for Large Vocabulary Continuous Speech Recognition
Recurrent neural networks (RNNs), especially long short-term memory (LSTM)
RNNs, are effective network for sequential task like speech recognition. Deeper
LSTM models perform well on large vocabulary continuous speech recognition,
because of their impressive learning ability. However, it is more difficult to
train a deeper network. We introduce a training framework with layer-wise
training and exponential moving average methods for deeper LSTM models. It is a
competitive framework that LSTM models of more than 7 layers are successfully
trained on Shenma voice search data in Mandarin and they outperform the deep
LSTM models trained by conventional approach. Moreover, in order for online
streaming speech recognition applications, the shallow model with low real time
factor is distilled from the very deep model. The recognition accuracy have
little loss in the distillation process. Therefore, the model trained with the
proposed training framework reduces relative 14\% character error rate,
compared to original model which has the similar real-time capability.
Furthermore, the novel transfer learning strategy with segmental Minimum
Bayes-Risk is also introduced in the framework. The strategy makes it possible
that training with only a small part of dataset could outperform full dataset
training from the beginning.