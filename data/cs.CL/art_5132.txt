LSICC: A Large Scale Informal Chinese Corpus
Deep learning based natural language processing model is proven powerful, but
need large-scale dataset. Due to the significant gap between the real-world
tasks and existing Chinese corpus, in this paper, we introduce a large-scale
corpus of informal Chinese. This corpus contains around 37 million book reviews
and 50 thousand netizen's comments to the news. We explore the informal words
frequencies of the corpus and show the difference between our corpus and the
existing ones. The corpus can be further used to train deep learning based
natural language processing tasks such as Chinese word segmentation, sentiment
analysis.