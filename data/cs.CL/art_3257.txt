word representation or word embedding in Persian text
Text processing is one of the sub-branches of natural language processing.
Recently, the use of machine learning and neural networks methods has been
given greater consideration. For this reason, the representation of words has
become very important. This article is about word representation or converting
words into vectors in Persian text. In this research GloVe, CBOW and skip-gram
methods are updated to produce embedded vectors for Persian words. In order to
train a neural networks, Bijankhan corpus, Hamshahri corpus and UPEC corpus
have been compound and used. Finally, we have 342,362 words that obtained
vectors in all three models for this words. These vectors have many usage for
Persian natural language processing.