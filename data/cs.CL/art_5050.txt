Towards Fluent Translations from Disfluent Speech
When translating from speech, special consideration for conversational speech
phenomena such as disfluencies is necessary. Most machine translation training
data consists of well-formed written texts, causing issues when translating
spontaneous speech. Previous work has introduced an intermediate step between
speech recognition (ASR) and machine translation (MT) to remove disfluencies,
making the data better-matched to typical translation text and significantly
improving performance. However, with the rise of end-to-end speech translation
systems, this intermediate step must be incorporated into the
sequence-to-sequence architecture. Further, though translated speech datasets
exist, they are typically news or rehearsed speech without many disfluencies
(e.g. TED), or the disfluencies are translated into the references (e.g.
Fisher). To generate clean translations from disfluent speech, cleaned
references are necessary for evaluation. We introduce a corpus of cleaned
target data for the Fisher Spanish-English dataset for this task. We compare
how different architectures handle disfluencies and provide a baseline for
removing disfluencies in end-to-end translation.