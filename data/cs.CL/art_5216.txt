Quantized-Dialog Language Model for Goal-Oriented Conversational Systems
We propose a novel methodology to address dialog learning in the context of
goal-oriented conversational systems. The key idea is to quantize the dialog
space into clusters and create a language model across the clusters, thus
allowing for an accurate choice of the next utterance in the conversation. The
language model relies on n-grams associated with clusters of utterances. This
quantized-dialog language model methodology has been applied to the end-to-end
goal-oriented track of the latest Dialog System Technology Challenges (DSTC6).
The objective is to find the correct system utterance from a pool of candidates
in order to complete a dialog between a user and an automated
restaurant-reservation system. Our results show that the technique proposed in
this paper achieves high accuracy regarding selection of the correct candidate
utterance, and outperforms other state-of-the-art approaches based on neural
networks.