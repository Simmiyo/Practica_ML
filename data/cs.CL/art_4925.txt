Predicting the Semantic Textual Similarity with Siamese CNN and LSTM
Semantic Textual Similarity (STS) is the basis of many applications in
Natural Language Processing (NLP). Our system combines convolution and
recurrent neural networks to measure the semantic similarity of sentences. It
uses a convolution network to take account of the local context of words and an
LSTM to consider the global context of sentences. This combination of networks
helps to preserve the relevant information of sentences and improves the
calculation of the similarity between sentences. Our model has achieved good
results and is competitive with the best state-of-the-art systems.