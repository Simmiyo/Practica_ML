Portuguese Word Embeddings: Evaluating on Word Analogies and Natural
  Language Tasks
Word embeddings have been found to provide meaningful representations for
words in an efficient way; therefore, they have become common in Natural
Language Processing sys- tems. In this paper, we evaluated different word
embedding models trained on a large Portuguese corpus, including both Brazilian
and European variants. We trained 31 word embedding models using FastText,
GloVe, Wang2Vec and Word2Vec. We evaluated them intrinsically on syntactic and
semantic analogies and extrinsically on POS tagging and sentence semantic
similarity tasks. The obtained results suggest that word analogies are not
appropriate for word embedding evaluation; task-specific evaluations appear to
be a better option.