Skeleton-to-Response: Dialogue Generation Guided by Retrieval Memory
For dialogue response generation, traditional generative models generate
responses solely from input queries. Such models rely on insufficient
information for generating a specific response since a certain query could be
answered in multiple ways. Consequentially, those models tend to output generic
and dull responses, impeding the generation of informative utterances.
Recently, researchers have attempted to fill the information gap by exploiting
information retrieval techniques. When generating a response for a current
query, similar dialogues retrieved from the entire training data are considered
as an additional knowledge source. While this may harvest massive information,
the generative models could be overwhelmed, leading to undesirable performance.
In this paper, we propose a new framework which exploits retrieval results via
a skeleton-then-response paradigm. At first, a skeleton is generated by
revising the retrieved responses. Then, a novel generative model uses both the
generated skeleton and the original query for response generation. Experimental
results show that our approaches significantly improve the diversity and
informativeness of the generated responses.