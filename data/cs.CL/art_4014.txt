On the Impact of Various Types of Noise on Neural Machine Translation
We examine how various types of noise in the parallel training data impact
the quality of neural machine translation systems. We create five types of
artificial noise and analyze how they degrade performance in neural and
statistical machine translation. We find that neural models are generally more
harmed by noise than statistical models. For one especially egregious type of
noise they learn to just copy the input sentence.