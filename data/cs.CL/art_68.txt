Structured Language Modeling for Speech Recognition
A new language model for speech recognition is presented. The model develops
hidden hierarchical syntactic-like structure incrementally and uses it to
extract meaningful information from the word history, thus complementing the
locality of currently used trigram models. The structured language model (SLM)
and its performance in a two-pass speech recognizer --- lattice decoding ---
are presented. Experiments on the WSJ corpus show an improvement in both
perplexity (PPL) and word error rate (WER) over conventional trigram models.