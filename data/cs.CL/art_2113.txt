Knowledge Representation via Joint Learning of Sequential Text and
  Knowledge Graphs
Textual information is considered as significant supplement to knowledge
representation learning (KRL). There are two main challenges for constructing
knowledge representations from plain texts: (1) How to take full advantages of
sequential contexts of entities in plain texts for KRL. (2) How to dynamically
select those informative sentences of the corresponding entities for KRL. In
this paper, we propose the Sequential Text-embodied Knowledge Representation
Learning to build knowledge representations from multiple sentences. Given each
reference sentence of an entity, we first utilize recurrent neural network with
pooling or long short-term memory network to encode the semantic information of
the sentence with respect to the entity. Then we further design an attention
model to measure the informativeness of each sentence, and build text-based
representations of entities. We evaluate our method on two tasks, including
triple classification and link prediction. Experimental results demonstrate
that our method outperforms other baselines on both tasks, which indicates that
our method is capable of selecting informative sentences and encoding the
textual information well into knowledge representations.