Discourse Coherence in the Wild: A Dataset, Evaluation and Methods
To date there has been very little work on assessing discourse coherence
methods on real-world data. To address this, we present a new corpus of
real-world texts (GCDC) as well as the first large-scale evaluation of leading
discourse coherence algorithms. We show that neural models, including two that
we introduce here (SentAvg and ParSeq), tend to perform best. We analyze these
performance differences and discuss patterns we observed in low coherence texts
in four domains.