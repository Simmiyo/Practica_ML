Static and Dynamic Vector Semantics for Lambda Calculus Models of
  Natural Language
Vector models of language are based on the contextual aspects of language,
the distributions of words and how they co-occur in text. Truth conditional
models focus on the logical aspects of language, compositional properties of
words and how they compose to form sentences. In the truth conditional
approach, the denotation of a sentence determines its truth conditions, which
can be taken to be a truth value, a set of possible worlds, a context change
potential, or similar. In the vector models, the degree of co-occurrence of
words in context determines how similar the meanings of words are. In this
paper, we put these two models together and develop a vector semantics for
language based on the simply typed lambda calculus models of natural language.
We provide two types of vector semantics: a static one that uses techniques
familiar from the truth conditional tradition and a dynamic one based on a form
of dynamic interpretation inspired by Heim's context change potentials. We show
how the dynamic model can be applied to entailment between a corpus and a
sentence and we provide examples.