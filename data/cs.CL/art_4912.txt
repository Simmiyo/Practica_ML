Neural Transition-based Syntactic Linearization
The task of linearization is to find a grammatical order given a set of
words. Traditional models use statistical methods. Syntactic linearization
systems, which generate a sentence along with its syntactic tree, have shown
state-of-the-art performance. Recent work shows that a multi-layer LSTM
language model outperforms competitive statistical syntactic linearization
systems without using syntax. In this paper, we study neural syntactic
linearization, building a transition-based syntactic linearizer leveraging a
feed-forward neural network, observing significantly better results compared to
LSTM language models on this task.