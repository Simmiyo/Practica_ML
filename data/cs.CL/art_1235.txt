Generating Simulations of Motion Events from Verbal Descriptions
In this paper, we describe a computational model for motion events in natural
language that maps from linguistic expressions, through a dynamic event
interpretation, into three-dimensional temporal simulations in a model.
Starting with the model from (Pustejovsky and Moszkowicz, 2011), we analyze
motion events using temporally-traced Labelled Transition Systems. We model the
distinction between path- and manner-motion in an operational semantics, and
further distinguish different types of manner-of-motion verbs in terms of the
mereo-topological relations that hold throughout the process of movement. From
these representations, we generate minimal models, which are realized as
three-dimensional simulations in software developed with the game engine,
Unity. The generated simulations act as a conceptual "debugger" for the
semantics of different motion verbs: that is, by testing for consistency and
informativeness in the model, simulations expose the presuppositions associated
with linguistic expressions and their compositions. Because the model
generation component is still incomplete, this paper focuses on an
implementation which maps directly from linguistic interpretations into the
Unity code snippets that create the simulations.