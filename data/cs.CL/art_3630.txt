Learning Joint Semantic Parsers from Disjoint Data
We present a new approach to learning semantic parsers from multiple
datasets, even when the target semantic formalisms are drastically different,
and the underlying corpora do not overlap. We handle such "disjoint" data by
treating annotations for unobserved formalisms as latent structured variables.
Building on state-of-the-art baselines, we show improvements both in
frame-semantic parsing and semantic dependency parsing by modeling them
jointly.