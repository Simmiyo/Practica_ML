Incorporating Subword Information into Matrix Factorization Word
  Embeddings
The positive effect of adding subword information to word embeddings has been
demonstrated for predictive models. In this paper we investigate whether
similar benefits can also be derived from incorporating subwords into counting
models. We evaluate the impact of different types of subwords (n-grams and
unsupervised morphemes), with results confirming the importance of subword
information in learning representations of rare and out-of-vocabulary words.