Joint Multi-Domain Learning for Automatic Short Answer Grading
One of the fundamental challenges towards building any intelligent tutoring
system is its ability to automatically grade short student answers. A typical
automatic short answer grading system (ASAG) grades student answers across
multiple domains (or subjects). Grading student answers requires building a
supervised machine learning model that evaluates the similarity of the student
answer with the reference answer(s). We observe that unlike typical textual
similarity or entailment tasks, the notion of similarity is not universal here.
On one hand, para-phrasal constructs of the language can indicate similarity
independent of the domain. On the other hand, two words, or phrases, that are
not strict synonyms of each other, might mean the same in certain domains.
Building on this observation, we propose JMD-ASAG, the first joint multidomain
deep learning architecture for automatic short answer grading that performs
domain adaptation by learning generic and domain-specific aspects from the
limited domain-wise training data. JMD-ASAG not only learns the domain-specific
characteristics but also overcomes the dependence on a large corpus by learning
the generic characteristics from the task-specific data itself. On a
large-scale industry dataset and a benchmarking dataset, we show that our model
performs significantly better than existing techniques which either learn
domain-specific models or adapt a generic similarity scoring model from a large
corpus. Further, on the benchmarking dataset, we report state-of-the-art
results against all existing non-neural and neural models.