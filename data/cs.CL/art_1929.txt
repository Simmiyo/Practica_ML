Evaluation method of word embedding by roots and affixes
Word embedding has been shown to be remarkably effective in a lot of Natural
Language Processing tasks. However, existing models still have a couple of
limitations in interpreting the dimensions of word vector. In this paper, we
provide a new approach---roots and affixes model(RAAM)---to interpret it from
the intrinsic structures of natural language. Also it can be used as an
evaluation measure of the quality of word embedding. We introduce the
information entropy into our model and divide the dimensions into two
categories, just like roots and affixes in lexical semantics. Then considering
each category as a whole rather than individually. We experimented with English
Wikipedia corpus. Our result show that there is a negative linear relation
between the two attributes and a high positive correlation between our model
and downstream semantic evaluation tasks.