Annotating and Modeling Empathy in Spoken Conversations
Empathy, as defined in behavioral sciences, expresses the ability of human
beings to recognize, understand and react to emotions, attitudes and beliefs of
others. The lack of an operational definition of empathy makes it difficult to
measure it. In this paper, we address two related problems in automatic
affective behavior analysis: the design of the annotation protocol and the
automatic recognition of empathy from spoken conversations. We propose and
evaluate an annotation scheme for empathy inspired by the modal model of
emotions. The annotation scheme was evaluated on a corpus of real-life, dyadic
spoken conversations. In the context of behavioral analysis, we designed an
automatic segmentation and classification system for empathy. Given the
different speech and language levels of representation where empathy may be
communicated, we investigated features derived from the lexical and acoustic
spaces. The feature development process was designed to support both the fusion
and automatic selection of relevant features from high dimensional space. The
automatic classification system was evaluated on call center conversations
where it showed significantly better performance than the baseline.