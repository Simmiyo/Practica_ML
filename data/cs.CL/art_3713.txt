Word Embedding Perturbation for Sentence Classification
In this technique report, we aim to mitigate the overfitting problem of
natural language by applying data augmentation methods. Specifically, we
attempt several types of noise to perturb the input word embedding, such as
Gaussian noise, Bernoulli noise, and adversarial noise, etc. We also apply
several constraints on different types of noise. By implementing these proposed
data augmentation methods, the baseline models can gain improvements on several
sentence classification tasks.