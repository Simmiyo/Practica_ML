Projecting Embeddings for Domain Adaptation: Joint Modeling of Sentiment
  Analysis in Diverse Domains
Domain adaptation for sentiment analysis is challenging due to the fact that
supervised classifiers are very sensitive to changes in domain. The two most
prominent approaches to this problem are structural correspondence learning and
autoencoders. However, they either require long training times or suffer
greatly on highly divergent domains. Inspired by recent advances in
cross-lingual sentiment analysis, we provide a novel perspective and cast the
domain adaptation problem as an embedding projection task. Our model takes as
input two mono-domain embedding spaces and learns to project them to a
bi-domain space, which is jointly optimized to (1) project across domains and
to (2) predict sentiment. We perform domain adaptation experiments on 20
source-target domain pairs for sentiment classification and report novel
state-of-the-art results on 11 domain pairs, including the Amazon domain
adaptation datasets and SemEval 2013 and 2016 datasets. Our analysis shows that
our model performs comparably to state-of-the-art approaches on domains that
are similar, while performing significantly better on highly divergent domains.
Our code is available at https://github.com/jbarnesspain/domain_blse