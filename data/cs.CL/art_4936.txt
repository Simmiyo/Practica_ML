Can Entropy Explain Successor Surprisal Effects in Reading?
Human reading behavior is sensitive to surprisal: more predictable words tend
to be read faster. Unexpectedly, this applies not only to the surprisal of the
word that is currently being read, but also to the surprisal of upcoming
(successor) words that have not been fixated yet. This finding has been
interpreted as evidence that readers can extract lexical information
parafoveally. Calling this interpretation into question, Angele et al. (2015)
showed that successor effects appear even in contexts in which those successor
words are not yet visible. They hypothesized that successor surprisal predicts
reading time because it approximates the reader's uncertainty about upcoming
words. We test this hypothesis on a reading time corpus using an LSTM language
model, and find that successor surprisal and entropy are independent predictors
of reading time. This independence suggests that entropy alone is unlikely to
be the full explanation for successor surprisal effects.