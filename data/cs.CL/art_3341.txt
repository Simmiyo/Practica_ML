Improving Word Vector with Prior Knowledge in Semantic Dictionary
Using low dimensional vector space to represent words has been very effective
in many NLP tasks. However, it doesn't work well when faced with the problem of
rare and unseen words. In this paper, we propose to leverage the knowledge in
semantic dictionary in combination with some morphological information to build
an enhanced vector space. We get an improvement of 2.3% over the
state-of-the-art Heidel Time system in temporal expression recognition, and
obtain a large gain in other name entity recognition (NER) tasks. The semantic
dictionary Hownet alone also shows promising results in computing lexical
similarity.