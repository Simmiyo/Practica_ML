Automatic Ranking of MT Outputs using Approximations
Since long, research on machine translation has been ongoing. Still, we do
not get good translations from MT engines so developed. Manual ranking of these
outputs tends to be very time consuming and expensive. Identifying which one is
better or worse than the others is a very taxing task. In this paper, we show
an approach which can provide automatic ranks to MT outputs (translations)
taken from different MT Engines and which is based on N-gram approximations. We
provide a solution where no human intervention is required for ranking systems.
Further we also show the evaluations of our results which show equivalent
results as that of human ranking.