Natural language understanding for task oriented dialog in the
  biomedical domain in a low resources context
In the biomedical domain, the lack of sharable datasets often limit the
possibility of developing natural language processing systems, especially
dialogue applications and natural language understanding models. To overcome
this issue, we explore data generation using templates and terminologies and
data augmentation approaches. Namely, we report our experiments using
paraphrasing and word representations learned on a large EHR corpus with
Fasttext and ELMo, to learn a NLU model without any available dataset. We
evaluate on a NLU task of natural language queries in EHRs divided in
slot-filling and intent classification sub-tasks. On the slot-filling task, we
obtain a F-score of 0.76 with the ELMo representation; and on the
classification task, a mean F-score of 0.71. Our results show that this method
could be used to develop a baseline system.