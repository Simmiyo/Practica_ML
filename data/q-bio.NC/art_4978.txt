A neuro-inspired architecture for unsupervised continual learning based
  on online clustering and hierarchical predictive coding
We propose that the Continual Learning desiderata can be achieved through a
neuro-inspired architecture, grounded on Mountcastle's cortical column
hypothesis. The proposed architecture involves a single module, called
Self-Taught Associative Memory (STAM), which models the function of a cortical
column. STAMs are repeated in multi-level hierarchies involving feedforward,
lateral and feedback connections. STAM networks learn in an unsupervised
manner, based on a combination of online clustering and hierarchical predictive
coding. This short paper only presents the architecture and its connections
with neuroscience. A mathematical formulation and experimental results will be
presented in an extended version of this paper.