Constraint satisfaction problems and neural networks: a statistical
  physics perspective
A new field of research is rapidly expanding at the crossroad between
statistical physics, information theory and combinatorial optimization. In
particular, the use of cutting edge statistical physics concepts and methods
allow one to solve very large constraint satisfaction problems like random
satisfiability, coloring, or error correction. Several aspects of these
developments should be relevant for the understanding of functional complexity
in neural networks. On the one hand the message passing procedures which are
used in these new algorithms are based on local exchange of information, and
succeed in solving some of the hardest computational problems. On the other
hand some crucial inference problems in neurobiology, like those generated in
multi-electrode recordings, naturally translate into hard constraint
satisfaction problems. This paper gives a non-technical introduction to this
field, emphasizing the main ideas at work in message passing strategies and
their possible relevance to neural networks modeling. It also introduces a new
message passing algorithm for inferring interactions between variables from
correlation data, which could be useful in the analysis of multi-electrode
recording data.