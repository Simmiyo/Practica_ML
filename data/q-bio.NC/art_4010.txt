Learning with a network of competing synapses
Competition between synapses arises in some forms of correlation-based
plasticity. Here we propose a game theory-inspired model of synaptic
interactions whose dynamics is driven by competition between synapses in their
weak and strong states, which are characterized by different timescales. The
learning of inputs and memory are meaningfully definable in an effective
description of networked synaptic populations. We study, numerically and
analytically, the dynamic responses of the effective system to various signal
types, particularly with reference to an existing empirical motor adaptation
model. The dependence of the system-level behavior on the synaptic parameters,
and the signal strength, is brought out in a clear manner, thus illuminating
issues such as those of optimal performance, and the functional role of
multiple timescales.