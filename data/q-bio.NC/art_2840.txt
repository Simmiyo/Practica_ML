Adaptive coordination of working-memory and reinforcement learning in
  non-human primates performing a trial-and-error problem solving task
Accumulating evidence suggest that human behavior in trial-and-error learning
tasks based on decisions between discrete actions may involve a combination of
reinforcement learning (RL) and working-memory (WM). While the understanding of
brain activity at stake in this type of tasks often involve the comparison with
non-human primate neurophysiological results, it is not clear whether monkeys
use similar combined RL and WM processes to solve these tasks. Here we analyzed
the behavior of five monkeys with computational models combining RL and WM. Our
model-based analysis approach enables to not only fit trial-by-trial choices
but also transient slowdowns in reaction times, indicative of WM use. We found
that the behavior of the five monkeys was better explained in terms of a
combination of RL and WM despite inter-individual differences. The same
coordination dynamics we used in a previous study in humans best explained the
behavior of some monkeys while the behavior of others showed the opposite
pattern, revealing a possible different dynamics of WM process. We further
analyzed different variants of the tested models to open a discussion on how
the long pretraining in these tasks may have favored particular coordination
dynamics between RL and WM. This points towards either inter-species
differences or protocol differences which could be further tested in humans.