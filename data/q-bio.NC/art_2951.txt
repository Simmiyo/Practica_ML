A Novel Method to Study Bottom-up Visual Saliency and its Neural
  Mechanism
In this study, we propose a novel method to measure bottom-up saliency maps
of natural images. In order to eliminate the influence of top-down signals,
backward masking is used to make stimuli (natural images) subjectively
invisible to subjects, however, the bottom-up saliency can still orient the
subjects attention. To measure this orientation/attention effect, we adopt the
cueing effect paradigm by deploying discrimination tasks at each location of an
image, and measure the discrimination performance variation across the image as
the attentional effect of the bottom-up saliency. Such attentional effects are
combined to construct a final bottomup saliency map. Based on the proposed
method, we introduce a new bottom-up saliency map dataset of natural images to
benchmark computational models. We compare several state-of-the-art saliency
models on the dataset. Moreover, the proposed paradigm is applied to
investigate the neural basis of the bottom-up visual saliency map by analyzing
psychophysical and fMRI experimental results. Our findings suggest that the
bottom-up saliency maps of natural images are constructed in V1. It provides a
strong scientific evidence to resolve the long standing dispute in neuroscience
about where the bottom-up saliency map is constructed in human brain.