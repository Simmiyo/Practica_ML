Ambiguity in language networks
Human language defines the most complex outcomes of evolution. The emergence
of such an elaborated form of communication allowed humans to create extremely
structured societies and manage symbols at different levels including, among
others, semantics. All linguistic levels have to deal with an astronomic
combinatorial potential that stems from the recursive nature of languages. This
recursiveness is indeed a key defining trait. However, not all words are
equally combined nor frequent. In breaking the symmetry between less and more
often used and between less and more meaning-bearing units, universal scaling
laws arise. Such laws, common to all human languages, appear on different
stages from word inventories to networks of interacting words. Among these
seemingly universal traits exhibited by language networks, ambiguity appears to
be a specially relevant component. Ambiguity is avoided in most computational
approaches to language processing, and yet it seems to be a crucial element of
language architecture. Here we review the evidence both from language network
architecture and from theoretical reasonings based on a least effort argument.
Ambiguity is shown to play an essential role in providing a source of language
efficiency, and is likely to be an inevitable byproduct of network growth.