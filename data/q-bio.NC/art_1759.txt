Independent neurons representing a finite set of stimuli: dependence of
  the mutual information on the number of units sampled
We study the capacity with which a system of independent neuron-like units
represents a given set of stimuli. We assume that each neuron provides a fixed
amount of information, and that the information provided by different neurons
has a random overlap. We derive analytically the dependence of the mutual
information between the set of stimuli and the neural responses on the number
of units sampled. For a large set of stimuli, the mutual information rises
linearly with the number of neurons, and later saturates exponentially at its
maximum value.