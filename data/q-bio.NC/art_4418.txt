Semantic Folding Theory And its Application in Semantic Fingerprinting
Human language is recognized as a very complex domain since decades. No
computer system has been able to reach human levels of performance so far. The
only known computational system capable of proper language processing is the
human brain. While we gather more and more data about the brain, its
fundamental computational processes still remain obscure. The lack of a sound
computational brain theory also prevents the fundamental understanding of
Natural Language Processing. As always when science lacks a theoretical
foundation, statistical modeling is applied to accommodate as many sampled
real-world data as possible. An unsolved fundamental issue is the actual
representation of language (data) within the brain, denoted as the
Representational Problem. Starting with Jeff Hawkins' Hierarchical Temporal
Memory (HTM) theory, a consistent computational theory of the human cortex, we
have developed a corresponding theory of language data representation: The
Semantic Folding Theory. The process of encoding words, by using a topographic
semantic space as distributional reference frame into a sparse binary
representational vector is called Semantic Folding and is the central topic of
this document. Semantic Folding describes a method of converting language from
its symbolic representation (text) into an explicit, semantically grounded
representation that can be generically processed by Hawkins' HTM networks. As
it turned out, this change in representation, by itself, can solve many complex
NLP problems by applying Boolean operators and a generic similarity function
like the Euclidian Distance. Many practical problems of statistical NLP
systems, like the high cost of computation, the fundamental incongruity of
precision and recall , the complex tuning procedures etc., can be elegantly
overcome by applying Semantic Folding.