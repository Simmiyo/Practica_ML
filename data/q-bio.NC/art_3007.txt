Fundamental principles of cortical computation: unsupervised learning
  with prediction, compression and feedback
There has been great progress in understanding of anatomical and functional
microcircuitry of the primate cortex. However, the fundamental principles of
cortical computation - the principles that allow the visual cortex to bind
retinal spikes into representations of objects, scenes and scenarios - have so
far remained elusive. In an attempt to come closer to understanding the
fundamental principles of cortical computation, here we present a functional,
phenomenological model of the primate visual cortex. The core part of the model
describes four hierarchical cortical areas with feedforward, lateral, and
recurrent connections. The three main principles implemented in the model are
information compression, unsupervised learning by prediction, and use of
lateral and top-down context. We show that the model reproduces key aspects of
the primate ventral stream of visual processing including Simple and Complex
cells in V1, increasingly complicated feature encoding, and increased
separability of object representations in higher cortical areas. The model
learns representations of the visual environment that allow for accurate
classification and state-of-the-art visual tracking performance on novel
objects.