Dendritic error backpropagation in deep cortical microcircuits
Animal behaviour depends on learning to associate sensory stimuli with the
desired motor command. Understanding how the brain orchestrates the necessary
synaptic modifications across different brain areas has remained a longstanding
puzzle. Here, we introduce a multi-area neuronal network model in which
synaptic plasticity continuously adapts the network towards a global desired
output. In this model synaptic learning is driven by a local dendritic
prediction error that arises from a failure to predict the top-down input given
the bottom-up activities. Such errors occur at apical dendrites of pyramidal
neurons where both long-range excitatory feedback and local inhibitory
predictions are integrated. When local inhibition fails to match excitatory
feedback an error occurs which triggers plasticity at bottom-up synapses at
basal dendrites of the same pyramidal neurons. We demonstrate the learning
capabilities of the model in a number of tasks and show that it approximates
the classical error backpropagation algorithm. Finally, complementing this
cortical circuit with a disinhibitory mechanism enables attention-like stimulus
denoising and generation. Our framework makes several experimental predictions
on the function of dendritic integration and cortical microcircuits, is
consistent with recent observations of cross-area learning, and suggests a
biological implementation of deep learning.