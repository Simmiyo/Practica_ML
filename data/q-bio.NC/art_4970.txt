Assessing the Contribution of Semantic Congruency to Multisensory
  Integration and Conflict Resolution
The efficient integration of multisensory observations is a key property of
the brain that yields the robust interaction with the environment. However,
artificial multisensory perception remains an open issue especially in
situations of sensory uncertainty and conflicts. In this work, we extend
previous studies on audio-visual (AV) conflict resolution in complex
environments. In particular, we focus on quantitatively assessing the
contribution of semantic congruency during an AV spatial localization task. In
addition to conflicts in the spatial domain (i.e. spatially misaligned
stimuli), we consider gender-specific conflicts with male and female avatars.
Our results suggest that while semantically related stimuli affect the
magnitude of the visual bias (perceptually shifting the location of the sound
towards a semantically congruent visual cue), humans still strongly rely on
environmental statistics to solve AV conflicts. Together with previously
reported results, this work contributes to a better understanding of how
multisensory integration and conflict resolution can be modelled in artificial
agents and robots operating in real-world environments.