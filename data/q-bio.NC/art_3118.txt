Object categorization in finer levels requires higher spatial
  frequencies, and therefore takes longer
The human visual system contains a hierarchical sequence of modules that take
part in visual perception at different levels of abstraction, i.e.,
superordinate, basic, and subordinate levels. One important question is to
identify the "entry" level at which the visual representation is commenced in
the process of object recognition. For a long time, it was believed that the
basic level had advantage over two others; a claim that has been challenged
recently. Here we used a series of psychophysics experiments, based on a rapid
presentation paradigm, as well as two computational models, with bandpass
filtered images to study the processing order of the categorization levels. In
these experiments, we investigated the type of visual information required for
categorizing objects in each level by varying the spatial frequency bands of
the input image. The results of our psychophysics experiments and computational
models are consistent. They indicate that the different spatial frequency
information had different effects on object categorization in each level. In
the absence of high frequency information, subordinate and basic level
categorization are performed inaccurately, while superordinate level is
performed well. This means that, low frequency information is sufficient for
superordinate level, but not for the basic and subordinate levels. These finer
levels require high frequency information, which appears to take longer to be
processed, leading to longer reaction times. Finally, to avoid the ceiling
effect, we evaluated the robustness of the results by adding different amounts
of noise to the input images and repeating the experiments. As expected, the
categorization accuracy decreased and the reaction time increased
significantly, but the trends were the same.This shows that our results are not
due to a ceiling effect.