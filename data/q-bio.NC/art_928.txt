Maximally Informative Stimuli and Tuning Curves for Sigmoidal
  Rate-Coding Neurons and Populations
A general method for deriving maximally informative sigmoidal tuning curves
for neural systems with small normalized variability is presented. The optimal
tuning curve is a nonlinear function of the cumulative distribution function of
the stimulus and depends on the mean-variance relationship of the neural
system. The derivation is based on a known relationship between Shannon's
mutual information and Fisher information, and the optimality of Jeffrey's
prior. It relies on the existence of closed-form solutions to the converse
problem of optimizing the stimulus distribution for a given tuning curve. It is
shown that maximum mutual information corresponds to constant Fisher
information only if the stimulus is uniformly distributed. As an example, the
case of sub-Poisson binomial firing statistics is analyzed in detail.