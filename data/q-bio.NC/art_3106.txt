Deducing the severity of psychiatric symptoms from the human voice
Psychiatric illnesses are often associated with multiple symptoms, whose
severity must be graded for accurate diagnosis and treatment. This grading is
usually done by trained clinicians based on human observations and judgments
made within doctor-patient sessions. Current research provides sufficient
reason to expect that the human voice may carry biomarkers or signatures of
many, if not all, these symptoms. Based on this conjecture, we explore the
possibility of objectively and automatically grading the symptoms of
psychiatric illnesses with reference to various standard psychiatric rating
scales. Using acoustic data from several clinician-patient interviews within
hospital settings, we use non-parametric models to learn and predict the
relations between symptom-ratings and voice. In the process, we show that
different articulatory-phonetic units of speech are able to capture the effects
of different symptoms differently, and use this to establish a plausible
methodology that could be employed for automatically grading psychiatric
symptoms for clinical purposes.