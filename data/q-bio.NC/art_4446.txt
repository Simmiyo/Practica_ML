A Single Model Explains both Visual and Auditory Precortical Coding
Precortical neural systems encode information collected by the senses, but
the driving principles of the encoding used have remained a subject of debate.
We present a model of retinal coding that is based on three constraints:
information preservation, minimization of the neural wiring, and response
equalization. The resulting novel version of sparse principal components
analysis successfully captures a number of known characteristics of the retinal
coding system, such as center-surround receptive fields, color opponency
channels, and spatiotemporal responses that correspond to magnocellular and
parvocellular pathways. Furthermore, when trained on auditory data, the same
model learns receptive fields well fit by gammatone filters, commonly used to
model precortical auditory coding. This suggests that efficient coding may be a
unifying principle of precortical encoding across modalities.