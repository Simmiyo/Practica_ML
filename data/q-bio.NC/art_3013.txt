Learning and Inferring Relations in Cortical Networks
A pressing scientific challenge is to understand how brains work. Of
particular interest is the neocortex,the part of the brain that is especially
large in humans, capable of handling a wide variety of tasks including visual,
auditory, language, motor, and abstract processing. These functionalities are
processed in different self-organized regions of the neocortical sheet, and yet
the anatomical structure carrying out the processing is relatively uniform
across the sheet. We are at a loss to explain, simulate, or understand such a
multi-functional homogeneous sheet-like computational structure - we do not
have computational models which work in this way. Here we present an important
step towards developing such models: we show how uniform modules of excitatory
and inhibitory neurons can be connected bidirectionally in a network that, when
exposed to input in the form of population codes, learns the input encodings as
well as the relationships between the inputs. STDP learning rules lead the
modules to self-organize into a relational network, which is able to infer
missing inputs,restore noisy signals, decide between conflicting inputs, and
combine cues to improve estimates. These networks show that it is possible for
a homogeneous network of spiking units to self-organize so as to provide
meaningful processing of its inputs. If such networks can be scaled up, they
could provide an initial computational model relevant to the large scale
anatomy of the neocortex.