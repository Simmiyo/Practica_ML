A Compression-Complexity Measure of Integrated Information
Quantifying integrated information is a leading approach towards building a
fundamental theory of consciousness. Integrated Information Theory (IIT) has
gained attention in this regard due to its theoretically strong framework.
However, it faces some limitations such as current state dependence,
computationally expensive and inability to be applied to real brain data. On
the other hand, Perturbational Complexity Index (PCI) is a clinical measure for
distinguishing different levels of consciousness. Though PCI claims to capture
the functional differentiation and integration in brain networks (similar to
IIT), its link to integrated information theories is rather weak. Inspired by
these two approaches, we propose a new measure - $\Phi^C$ using a novel
compression-complexity perspective that serves as a bridge between the two, for
the first time. $\Phi^C$ is founded on the principles of lossless data
compression based complexity measures which characterize the dynamical
complexity of brain networks. $\Phi^{C}$ exhibits following salient
innovations: (i) mathematically well bounded, (ii) negligible current state
dependence unlike $\Phi$, (iii) integrated information measured as
compression-complexity rather than as an infotheoretic quantity, and (iv)
faster to compute since number of atomic bipartitions scales linearly with the
number of nodes of the network, thus avoiding combinatorial explosion. Our
computer simulations show that $\Phi^C$ has similar hierarchy to $<\Phi>$ for
several multiple-node networks and it demonstrates a rich interplay between
differentiation, integration and entropy of the nodes of a network. $\Phi^C$ is
a promising heuristic measure to characterize the quantity of integrated
information (and hence a measure of quantity of consciousness) in larger
networks like human brain and provides an opportunity to test the predictions
of brain complexity on real neural data.