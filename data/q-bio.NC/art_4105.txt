The Spatial Real and Virtual Sound Stimuli Optimization for the Auditory
  BCI
The paper presents results from a project aiming to create horizontally
distributed surround sound sources and virtual sound images as auditory BCI
(aBCI) stimuli. The purpose is to create evoked brain wave response patterns
depending on attended or ignored sound directions. We propose to use a modified
version of the vector based amplitude panning (VBAP) approach to achieve the
goal. The so created spatial sound stimulus system for the novel oddball aBCI
paradigm allows us to create a multi-command experimental environment with very
encouraging results reported in this paper. We also present results showing
that a modulation of the sound image depth changes also the subject responses.
Finally, we also compare the proposed virtual sound approach with the
traditional one based on real sound sources generated from the real loudspeaker
directions. The so obtained results confirm the hypothesis of the possibility
to modulate independently the brain responses to spatial types and depths of
sound sources which allows for the development of the novel multi-command aBCI.