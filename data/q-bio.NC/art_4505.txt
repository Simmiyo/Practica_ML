Predictive Coding-based Deep Dynamic Neural Network for Visuomotor
  Learning
This study presents a dynamic neural network model based on the predictive
coding framework for perceiving and predicting the dynamic visuo-proprioceptive
patterns. In our previous study [1], we have shown that the deep dynamic neural
network model was able to coordinate visual perception and action generation in
a seamless manner. In the current study, we extended the previous model under
the predictive coding framework to endow the model with a capability of
perceiving and predicting dynamic visuo-proprioceptive patterns as well as a
capability of inferring intention behind the perceived visuomotor information
through minimizing prediction error. A set of synthetic experiments were
conducted in which a robot learned to imitate the gestures of another robot in
a simulation environment. The experimental results showed that with given
intention states, the model was able to mentally simulate the possible incoming
dynamic visuo-proprioceptive patterns in a top-down process without the inputs
from the external environment. Moreover, the results highlighted the role of
minimizing prediction error in inferring underlying intention of the perceived
visuo-proprioceptive patterns, supporting the predictive coding account of the
mirror neuron systems. The results also revealed that minimizing prediction
error in one modality induced the recall of the corresponding representation of
another modality acquired during the consolidative learning of raw-level
visuo-proprioceptive patterns.