Linear-Nonlinear-Poisson Neuron Networks Perform Bayesian Inference On
  Boltzmann Machines
One conjecture in both deep learning and classical connectionist viewpoint is
that the biological brain implements certain kinds of deep networks as its
back-end. However, to our knowledge, a detailed correspondence has not yet been
set up, which is important if we want to bridge between neuroscience and
machine learning. Recent researches emphasized the biological plausibility of
Linear-Nonlinear-Poisson (LNP) neuron model. We show that with neurally
plausible settings, the whole network is capable of representing any Boltzmann
machine and performing a semi-stochastic Bayesian inference algorithm lying
between Gibbs sampling and variational inference.