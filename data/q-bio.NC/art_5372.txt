Neural Architectures for Robot Intelligence
We argue that the direct experimental approaches to elucidate the
architecture of higher brains may benefit from insights gained from exploring
the possibilities and limits of artificial control architectures for robot
systems. We present some of our recent work that has been motivated by that
view and that is centered around the study of various aspects of hand actions
since these are intimately linked with many higher cognitive abilities. As
examples, we report on the development of a modular system for the recognition
of continuous hand postures based on neural nets, the use of vision and tactile
sensing for guiding prehensile movements of a multifingered hand, and the
recognition and use of hand gestures for robot teaching.
  Regarding the issue of learning, we propose to view real-world learning from
the perspective of data mining and to focus more strongly on the imitation of
observed actions instead of purely reinforcement-based exploration. As a
concrete example of such an effort we report on the status of an ongoing
project in our lab in which a robot equipped with an attention system with a
neurally inspired architecture is taught actions by using hand gestures in
conjunction with speech commands. We point out some of the lessons learnt from
this system, and discuss how systems of this kind can contribute to the study
of issues at the junction between natural and artificial cognitive systems.