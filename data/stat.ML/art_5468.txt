Marginal likelihood based model comparison in Fuzzy Bayesian Learning
In a recent paper [1] we introduced the Fuzzy Bayesian Learning (FBL)
paradigm where expert opinions can be encoded in the form of fuzzy rule bases
and the hyper-parameters of the fuzzy sets can be learned from data using a
Bayesian approach. The present paper extends this work for selecting the most
appropriate rule base among a set of competing alternatives, which best
explains the data, by calculating the model evidence or marginal likelihood. We
explain why this is an attractive alternative over simply minimizing a mean
squared error metric of prediction and show the validity of the proposition
using synthetic examples and a real world case study in the financial services
sector.