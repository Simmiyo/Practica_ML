Approximate cross-validation formula for Bayesian linear regression
Cross-validation (CV) is a technique for evaluating the ability of
statistical models/learning systems based on a given data set. Despite its wide
applicability, the rather heavy computational cost can prevent its use as the
system size grows. To resolve this difficulty in the case of Bayesian linear
regression, we develop a formula for evaluating the leave-one-out CV error
approximately without actually performing CV. The usefulness of the developed
formula is tested by statistical mechanical analysis for a synthetic model.
This is confirmed by application to a real-world supernova data set as well.