Exploring the Entire Regularization Path for the Asymmetric Cost Linear
  Support Vector Machine
We propose an algorithm for exploring the entire regularization path of
asymmetric-cost linear support vector machines. Empirical evidence suggests the
predictive power of support vector machines depends on the regularization
parameters of the training algorithms. The algorithms exploring the entire
regularization paths have been proposed for single-cost support vector machines
thereby providing the complete knowledge on the behavior of the trained model
over the hyperparameter space. Considering the problem in two-dimensional
hyperparameter space though enables our algorithm to maintain greater
flexibility in dealing with special cases and sheds light on problems
encountered by algorithms building the paths in one-dimensional spaces. We
demonstrate two-dimensional regularization paths for linear support vector
machines that we train on synthetic and real data.