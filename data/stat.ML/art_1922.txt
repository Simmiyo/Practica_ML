Inference-less Density Estimation using Copula Bayesian Networks
We consider learning continuous probabilistic graphical models in the face of
missing data. For non-Gaussian models, learning the parameters and structure of
such models depends on our ability to perform efficient inference, and can be
prohibitive even for relatively modest domains. Recently, we introduced the
Copula Bayesian Network (CBN) density model - a flexible framework that
captures complex high-dimensional dependency structures while offering direct
control over the univariate marginals, leading to improved generalization. In
this work we show that the CBN model also offers significant computational
advantages when training data is partially observed. Concretely, we leverage on
the specialized form of the model to derive a computationally amenable learning
objective that is a lower bound on the log-likelihood function. Importantly,
our energy-like bound circumvents the need for costly inference of an auxiliary
distribution, thus facilitating practical learning of highdimensional
densities. We demonstrate the effectiveness of our approach for learning the
structure and parameters of a CBN model for two reallife continuous domains.