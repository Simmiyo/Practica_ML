One Class Splitting Criteria for Random Forests
Random Forests (RFs) are strong machine learning tools for classification and
regression. However, they remain supervised algorithms, and no extension of RFs
to the one-class setting has been proposed, except for techniques based on
second-class sampling. This work fills this gap by proposing a natural
methodology to extend standard splitting criteria to the one-class setting,
structurally generalizing RFs to one-class classification. An extensive
benchmark of seven state-of-the-art anomaly detection algorithms is also
presented. This empirically demonstrates the relevance of our approach.