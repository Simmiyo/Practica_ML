Privacy for Free: Posterior Sampling and Stochastic Gradient Monte Carlo
We consider the problem of Bayesian learning on sensitive datasets and
present two simple but somewhat surprising results that connect Bayesian
learning to "differential privacy:, a cryptographic approach to protect
individual-level privacy while permiting database-level utility. Specifically,
we show that that under standard assumptions, getting one single sample from a
posterior distribution is differentially private "for free". We will see that
estimator is statistically consistent, near optimal and computationally
tractable whenever the Bayesian model of interest is consistent, optimal and
tractable. Similarly but separately, we show that a recent line of works that
use stochastic gradient for Hybrid Monte Carlo (HMC) sampling also preserve
differentially privacy with minor or no modifications of the algorithmic
procedure at all, these observations lead to an "anytime" algorithm for
Bayesian learning under privacy constraint. We demonstrate that it performs
much better than the state-of-the-art differential private methods on synthetic
and real datasets.