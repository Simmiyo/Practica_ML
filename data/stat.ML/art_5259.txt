An Integrated Simulator and Dataset that Combines Grasping and Vision
  for Deep Learning
Deep learning is an established framework for learning hierarchical data
representations. While compute power is in abundance, one of the main
challenges in applying this framework to robotic grasping has been obtaining
the amount of data needed to learn these representations, and structuring the
data to the task at hand. Among contemporary approaches in the literature, we
highlight key properties that have encouraged the use of deep learning
techniques, and in this paper, detail our experience in developing a simulator
for collecting cylindrical precision grasps of a multi-fingered dexterous
robotic hand.