A local approach to estimation in discrete loglinear models
We consider two connected aspects of maximum likelihood estimation of the
parameter for high-dimensional discrete graphical models: the existence of the
maximum likelihood estimate (mle) and its computation.
  When the data is sparse, there are many zeros in the contingency table and
the maximum likelihood estimate of the parameter may not exist. Fienberg and
Rinaldo (2012) have shown that the mle does not exists iff the data vector
belongs to a face of the so-called marginal cone spanned by the rows of the
design matrix of the model. Identifying these faces in high-dimension is
challenging. In this paper, we take a local approach : we show that one such
face, albeit possibly not the smallest one, can be identified by looking at a
collection of marginal graphical models generated by induced subgraphs
$G_i,i=1,\ldots,k$ of $G$. This is our first contribution.
  Our second contribution concerns the composite maximum likelihood estimate.
When the dimension of the problem is large, estimating the parameters of a
given graphical model through maximum likelihood is challenging, if not
impossible. The traditional approach to this problem has been local with the
use of composite likelihood based on local conditional likelihoods.
  A more recent development is to have the components of the composite
likelihood be marginal likelihoods centred around each $v$. We first show that
the estimates obtained by consensus through local conditional and marginal
likelihoods are identical. We then study the asymptotic properties of the
composite maximum likelihood estimate when both the dimension of the model and
the sample size $N$ go to infinity.