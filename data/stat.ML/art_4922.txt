On Lower Bounds for Regret in Reinforcement Learning
This is a brief technical note to clarify the state of lower bounds on regret
for reinforcement learning. In particular, this paper:
  - Reproduces a lower bound on regret for reinforcement learning, similar to
the result of Theorem 5 in the journal UCRL2 paper (Jaksch et al 2010).
  - Clarifies that the proposed proof of Theorem 6 in the REGAL paper (Bartlett
and Tewari 2009) does not hold using the standard techniques without further
work. We suggest that this result should instead be considered a conjecture as
it has no rigorous proof.
  - Suggests that the conjectured lower bound given by (Bartlett and Tewari
2009) is incorrect and, in fact, it is possible to improve the scaling of the
upper bound to match the weaker lower bounds presented in this paper.
  We hope that this note serves to clarify existing results in the field of
reinforcement learning and provides interesting motivation for future work.