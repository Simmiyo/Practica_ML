Deep scattering transform applied to note onset detection and instrument
  recognition
Automatic Music Transcription (AMT) is one of the oldest and most
well-studied problems in the field of music information retrieval. Within this
challenging research field, onset detection and instrument recognition take
important places in transcription systems, as they respectively help to
determine exact onset times of notes and to recognize the corresponding
instrument sources. The aim of this study is to explore the usefulness of
multiscale scattering operators for these two tasks on plucked string
instrument and piano music. After resuming the theoretical background and
illustrating the key features of this sound representation method, we evaluate
its performances comparatively to other classical sound representations. Using
both MIDI-driven datasets with real instrument samples and real musical pieces,
scattering is proved to outperform other sound representations for these AMT
subtasks, putting forward its richer sound representation and invariance
properties.