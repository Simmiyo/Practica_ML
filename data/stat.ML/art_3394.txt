Computationally Efficient Bayesian Learning of Gaussian Process State
  Space Models
Gaussian processes allow for flexible specification of prior assumptions of
unknown dynamics in state space models. We present a procedure for efficient
Bayesian learning in Gaussian process state space models, where the
representation is formed by projecting the problem onto a set of approximate
eigenfunctions derived from the prior covariance structure. Learning under this
family of models can be conducted using a carefully crafted particle MCMC
algorithm. This scheme is computationally efficient and yet allows for a fully
Bayesian treatment of the problem. Compared to conventional system
identification tools or existing learning methods, we show competitive
performance and reliable quantification of uncertainties in the model.