Complex Support Vector Machines for Regression and Quaternary
  Classification
The paper presents a new framework for complex Support Vector Regression as
well as Support Vector Machines for quaternary classification. The method
exploits the notion of widely linear estimation to model the input-out relation
for complex-valued data and considers two cases: a) the complex data are split
into their real and imaginary parts and a typical real kernel is employed to
map the complex data to a complexified feature space and b) a pure complex
kernel is used to directly map the data to the induced complex feature space.
The recently developed Wirtinger's calculus on complex reproducing kernel
Hilbert spaces (RKHS) is employed in order to compute the Lagrangian and derive
the dual optimization problem. As one of our major results, we prove that any
complex SVM/SVR task is equivalent with solving two real SVM/SVR tasks
exploiting a specific real kernel which is generated by the chosen complex
kernel. In particular, the case of pure complex kernels leads to the generation
of new kernels, which have not been considered before. In the classification
case, the proposed framework inherently splits the complex space into four
parts. This leads naturally in solving the four class-task (quaternary
classification), instead of the typical two classes of the real SVM. In turn,
this rationale can be used in a multiclass problem as a split-class scenario
based on four classes, as opposed to the one-versus-all method; this can lead
to significant computational savings. Experiments demonstrate the effectiveness
of the proposed framework for regression and classification tasks that involve
complex data.