Interpretable Classification Models for Recidivism Prediction
We investigate a long-debated question, which is how to create predictive
models of recidivism that are sufficiently accurate, transparent, and
interpretable to use for decision-making. This question is complicated as these
models are used to support different decisions, from sentencing, to determining
release on probation, to allocating preventative social services. Each use case
might have an objective other than classification accuracy, such as a desired
true positive rate (TPR) or false positive rate (FPR). Each (TPR, FPR) pair is
a point on the receiver operator characteristic (ROC) curve. We use popular
machine learning methods to create models along the full ROC curve on a wide
range of recidivism prediction problems. We show that many methods (SVM, Ridge
Regression) produce equally accurate models along the full ROC curve. However,
methods that designed for interpretability (CART, C5.0) cannot be tuned to
produce models that are accurate and/or interpretable. To handle this
shortcoming, we use a new method known as SLIM (Supersparse Linear Integer
Models) to produce accurate, transparent, and interpretable models along the
full ROC curve. These models can be used for decision-making for many different
use cases, since they are just as accurate as the most powerful black-box
machine learning models, but completely transparent, and highly interpretable.